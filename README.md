# desafio-stack-tecnologias

## ğŸ™‹ Sobre Mim

ğŸ‘¨â€ğŸ’» Leonardo Souza  
Engenheiro de Dados  
ğŸ“§ leo.andrade.bsouza@gmail.com  
ğŸ”— [linkedin.com/in/]()

# ğŸ› ï¸ Desafio TÃ©cnico - Stack Tecnologias

Este repositÃ³rio contÃ©m a soluÃ§Ã£o desenvolvida por mim, Leonardo Souza, para o desafio tÃ©cnico da Stack Tecnologias. A proposta foi construir um pipeline de dados moderno e completo, utilizando os principais serviÃ§os do ecossistema AWS, com foco em boas prÃ¡ticas de engenharia de dados, seguranÃ§a, versionamento e governanÃ§a.

---

## ğŸ“Œ Objetivo do Projeto

Construir um pipeline de ingestÃ£o, transformaÃ§Ã£o e exposiÃ§Ã£o de dados em arquitetura de Data Lake, aplicando:

- PySpark com Delta Lake no AWS Glue
- OrganizaÃ§Ã£o em camadas Medallion (Bronze, Silver, Gold)
- CatalogaÃ§Ã£o com Glue Data Catalog
- Particionamento e incrementalidade
- Carga final em banco (PostgreSQL)
- OrquestraÃ§Ã£o com AWS Step Functions
- SeguranÃ§a com IAM e SSE-KMS
- OrganizaÃ§Ã£o escalÃ¡vel no S3

---

## ğŸ§± Arquitetura do Projeto

### ğŸ”· Medallion Architecture

| Camada | Objetivo | Formato | Qualidade dos dados |
|--------|----------|---------|----------------------|
| Dropzone | Ãrea de entrada dos dados brutos | CSV | Sem garantia |
| Bronze   | Dados tÃ©cnicos com metadados e particionamento | Delta Lake | Raw confiÃ¡vel |
| Silver   | Dados otimizados com merge/upsert e deduplicaÃ§Ã£o | Delta Lake | Pronto para consumo tÃ©cnico |
| Gold     | Dados agregados para anÃ¡lise de negÃ³cio | Delta Lake | Pronto para BI e relatÃ³rios |

---

## ğŸª£ Buckets Utilizados

Todos seguem as boas prÃ¡ticas: versionamento, bloqueio de acesso pÃºblico e criptografia SSE-KMS.

| Bucket | Finalidade |
|--------|------------|
| `leonardo-souza-dropzone-dev-us-east-1` | Entrada de arquivos CSV brutos |
| `leonardo-souza-bronze-dev-us-east-1`   | Dados convertidos para Delta, com metadados |
| `leonardo-souza-silver-dev-us-east-1`   | Dados deduplicados e com merge incremental |
| `leonardo-souza-gold-dev-us-east-1`     | Dados agregados por perÃ­odo e tipo de pagamento |

---

## âš™ï¸ Componentes e Processamento

### ğŸ”¸ Bronze Job (ETL)
- Leitura de CSV da Dropzone
- InclusÃ£o de colunas tÃ©cnicas: `ingestion_timestamp`, `source_file`, `year`, `month`
- Escrita como Delta com particionamento
- CriaÃ§Ã£o de tabela externa no Glue Catalog:
  - `bronze_layer_manual_files.kaggle_nyc_yellow_taxi_trip`

### ğŸ”¸ Silver Job (Delta Merge)
- Leitura da tabela Bronze
- Cast de colunas, validaÃ§Ã£o de datas e filtros mÃ­nimos
- DeduplicaÃ§Ã£o por chave composta
- Escrita incremental com **merge/upsert**
- Registro no Glue Catalog:
  - `silver_layer_manual_files.kaggle_nyc_taxi_trip`

### ğŸ”¸ Gold Job (AgregaÃ§Ãµes)
- Leitura da Silver
- AgregaÃ§Ã£o por `year`, `month` e `payment_type`
- MÃ©tricas calculadas: total de corridas, total arrecadado
- Escrita em Delta com **merge/upsert**
- Registro no Glue Catalog:
  - `gold_layer_manual_files.kaggle_nyc_taxi_trip`

---

## ğŸ§  EstratÃ©gias adotadas

- **Partition Discovery**: `year` e `month` para facilitar queries otimizadas
- **Delta Lake**: usado em todas as camadas para permitir versionamento e merge eficiente
- **Upsert (MERGE)**: implementado nas camadas Silver e Gold
- **Job modularizado**: com funÃ§Ãµes bem separadas para `extract`, `transform`, `merge` e `catalog`
- **Log estruturado**: via `logger` em todas as camadas

---

## ğŸ” SeguranÃ§a e Acesso

- IAM User pessoal criado com acesso restrito (sem uso de root)
- IAM Role exclusiva para o Glue com polÃ­tica customizada
- Criptografia dos buckets com SSE-KMS
- Conector JDBC configurado com seguranÃ§a para acesso ao PostgreSQL no RDS
- Banco de dados RDS nÃ£o exposto publicamente

---

## ğŸ“· EvidÃªncias da ExecuÃ§Ã£o

Inclui screenshots anexadas:

- ConexÃ£o com PostgreSQL no Glue
- ExecuÃ§Ã£o bem-sucedida dos jobs Bronze, Silver e Gold
- CatÃ¡logo de tabelas no Glue
- OrquestraÃ§Ã£o com AWS Step Functions

---

## ğŸš€ PrÃ³ximos Passos

- ImplementaÃ§Ã£o de monitoramento com CloudWatch/SNS
- ExportaÃ§Ã£o dos dados da Gold para dashboards ou consultas BI via RDS/Redshift

---

## ğŸ—‚ï¸ Estrutura do RepositÃ³rio

desafio-stack-tecnologias/
â”œâ”€â”€ captura_de_tela_aws/
â”‚   â”œâ”€â”€ aurora_rds_postgresql_connection.png
â”‚   â”œâ”€â”€ bronze_job_execution.png
â”‚   â”œâ”€â”€ connector_rds_postgresql_to_glue.png
â”‚   â”œâ”€â”€ glue_studio_jobs.png
â”‚   â”œâ”€â”€ gold_job_execution.png
â”‚   â”œâ”€â”€ silver_job_execution.png
â”‚   â””â”€â”€ step_functions.png
â”œâ”€â”€ data_ingestion/
â”‚   â”œâ”€â”€ bronze_job.py
â”‚   â”œâ”€â”€ silver_job.py
â”‚   â””â”€â”€ gold_job.py
â”œâ”€â”€ README.md
